# -*- coding: utf-8 -*-
"""House Price Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_NSdPn6rQXxeELE8NpOTolmv5ObH6Oi6
"""

import time
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn.datasets
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
# from sklearn.ensemble import RandomForestRegressor
from sklearn import metrics

house_price_dataset = sklearn.datasets.fetch_california_housing()

print(house_price_dataset)

print(house_price_dataset)

#loading the dataset to a pandas DataFrame
house_price_dataframe =pd.DataFrame(house_price_dataset.data, columns= house_price_dataset.feature_names)

# Printing the First 5 rows of our DataFrame
house_price_dataframe.head()

# add the target column to DataFrame
house_price_dataframe['price'] = house_price_dataset.target

house_price_dataframe.head()

#checking the number of rows and columns in the data frame
house_price_dataframe.shape

#checking the mising values
house_price_dataframe.isnull().sum

#statistical measures of the dataset
house_price_dataframe.describe()

"""#understanding the correlation between various features in the dataset
# 1. Positive Correlation-- one increases the other increases
# 2. Negative Correlation-- one decreases the other decreases
"""

correlation = house_price_dataframe.corr()

plt.figure(figsize=(10,10))
sns.heatmap(correlation, cbar=True, square= True, fmt='.1f',annot = True, annot_kws={'size':9}, cmap='Blues')

#Splitting th data and target
X = house_price_dataframe.drop(['price'], axis=1)
Y = house_price_dataframe['price']

print(X)
print(Y)

X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2, random_state=2)

print(X.shape, X_train.shape, X_test.shape)

# model = RandomForestRegressor(n_estimators=100, max_depth=None, random_state=2)

model = XGBRegressor(n_estimators=100, max_depth=None, random_state=2)

start_time = time.time()

#training the model with X_train
model.fit(X_train, Y_train)

end_time = time.time()

training_time = end_time - start_time
# print(f"Training time for Random Forest Regressor: {training_time} seconds")
# print(f"Training time for XGBRegressor: {training_time} seconds")

#accuracy for prediction on training data
training_data_prediction = model.predict(X_train)

print(training_data_prediction)

# R squared error
score_1 = metrics.r2_score(Y_train, training_data_prediction)

# Mean Absolute Error
score_2 = metrics.mean_absolute_error(Y_train, training_data_prediction)

print("R squared error : ", score_1)
print('Mean Absolute Error : ', score_2)

"""Visualizing the actual Price vs Predicted Price"""

plt.scatter(Y_train, training_data_prediction)
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Actual Price vs Predicted Price")
plt.show()

"""Prediction for Test Data"""

# accuracy for prediction on test data
test_data_prediction = model.predict(X_test)

# R squared error
score_1 = metrics.r2_score(Y_test, test_data_prediction)

# Mean Absolute Error
score_2 = metrics.mean_absolute_error(Y_test, test_data_prediction)

print("R squared error : ", score_1)
print('Mean Absolute Error : ', score_2)

accuracy_score = metrics.r2_score(Y_test, test_data_prediction)
print(accuracy_score)

import joblib

# Save the trained model
joblib.dump(model, 'model.pkl')